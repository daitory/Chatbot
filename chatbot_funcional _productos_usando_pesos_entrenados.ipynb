{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\my\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\my\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "import unidecode\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmantizer=WordNetLemmatizer()\n",
    "data = open(\"Json_detalle_productos_bot.json\").read()\n",
    "\n",
    "intents=json.loads(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'Back-Test', 'patterns': ['back', 'retrospectivas', 'retrospectiva'], 'responses': ['- Aplicación de Back-Testing  a Modelos de estimación del Valor en Riesgo, para verificar su correcto ajuste a la Historia de la EIF.- Se recomienda Aplicar Backtest a cada Modelo propuesto.']}, {'tag': 'CLTV Based Pricing', 'patterns': ['cltv', 'lifetime'], 'responses': ['- Modelo de Precios en base al Valor del Cliente en el Tiempo, con un enfoque Estadístico Clásico - Comportamental, que persigue un ajuste del valor de cliente en función del retorno que genera hacia la Institución Financiera.- Funciona como complemento a la visión Riesgo Céntrica del Pricing. - Mediante la aplicación conjunta de los modelos de Pricing se consigue un ajuste Dinámico del Pricing.']}, {'tag': 'Atrittion Score', 'patterns': ['atrittion', 'atrittion'], 'responses': ['- Modelo de Retención, basado en Estadística Clásica, para predecir la Probabilidad de Deserción de Clientes.- Permite generar estrategías de retención en función de la probabilidad que presentan los prospectos para dejar de utilizar sus productos financieros.- En combinación con modelos de venta, originación y clasificación de portafolio, resulta muy efectivo para focalizar los esfuerzos en los clientes que realmente valgan la pena.']}, {'tag': 'Pasives Behaviour Model', 'patterns': ['pasives behaviour', 'pasivos', 'pasivo'], 'responses': ['- Modelo Comportamental, basado en Estadística Clásica, para predecir la Probabilidad de Incumplimiento de Clientes con productos en la Institución.- Tiene un Performance Alto, y presenta Mucha Estabilidad en el Tiempo , tal y como suelen tener sus homólogos basados en Productos Activos.-  Suelen combinarse con otros modelos comportamentales para dar una visión más completa del cliente.']}, {'tag': 'VaR Models', 'patterns': ['valor en riesgo', 'value at risk'], 'responses': ['- Modelos de Valor en Riesgo (Value At Risk) , con enfoque de  Estadística Clásica, para estimar el monto que se espera perder, bajo cierto nivel de certidumbre, en función de la composición del portafolio  estudiado.- Se proponen varios modelos de estudio, como indicadores de seguimiento de la cartera de Inversiones.-  Debe combinarse con Modelos de Pérdidas Esperadas.']}, {'tag': 'Collections Score', 'patterns': ['collections', 'collections', 'cobranzas'], 'responses': ['- Modelo de Cobranzas , basado en Estadística Clásica , para Administrar Tratamientos a Clientes con productos Activos en la Institución Financiera.   Pudiendo, acoplarse a los tratamientos de cobros impuestos por la EIF, pero con el aditivo preventivo  de los modelos que utiliza como base. - Resulta Altamente Eficaz en la prevención del deterioro de clientes con oportunidades de mejora, dado que establece tratamientos desde la premora.- Permite focalizar los esfuerzos  para mejorar su efectividad y eficientizar las labores del Área de Cobros.']}, {'tag': 'Crossell - Upsell Model', 'patterns': ['crossell upsell model', 'ventas cruzadas'], 'responses': ['- Modelo para Ventas Cruzadas, basado en Estadística Clásica, fundamentado en el Comportamiento  y uso de los productos Financieros de los Clientes.- En combinación de los modelos de Probabilidad de Aceptación de Oferta, Admisión , Pricing , Clasificación de Portafolio, permite focalizar los esfuerzos en clientes que generen mayor retorno para la Institución.']}, {'tag': 'Early Warnings', 'patterns': ['early warnings', 'alertas tempranas'], 'responses': ['- Modelo Comportamental aplicado a Cobranzas, basado en Estadística Clásica, para predecir la Probabilidad de Default de Clientes con Productos activos  en estado de Premora.- Sirve para imponer tratamientos preventivos efectivos ante clientes que presentan mayor probabilidad de incumplir con sus facilidades crediticia, pese a que, al momento de realizar el estudio se encuentran en premora.- Son ampliamente utilizados en el Sector Financiero, para asegurar la efectividad de la Cobranza, y suelen combinarse con otros modelos Comportamentales para generar estrategias adecuadas para cobro, bajo un Modelo de Cobranzas.']}, {'tag': 'Credit Admission Scores', 'patterns': ['credit admission', 'originacion', 'otorgamiento'], 'responses': ['- Modelo de Otorgamiento de Préstamos, basado en Estadística Clásica, para predecir la Probabilidad Default de Prospectos a Clientes.  - Es uno de los modelos más utilizados y reconocidos  internacionalmente  por su buen desempeño, simplicidad y resistencia al paso del tiempo.- Puede ser reacondicionado en el tiempo, a menos que haya sufrido un deterioro muy fuerte.- Sirve como punto de partida para estudios de Pricing , Especificaciones de Punto de Corte y Políticas.']}, {'tag': 'Loss Given By Default', 'patterns': ['loss given by default', 'lgd', 'perdidas_dado_incumplimiento'], 'responses': ['- Estimación de Pérdidas Financieras dado el Incumplimiento de Préstamos, en función de Modelos Estadísticos Clásicos.- Forma parte de la Metodología de Basilea, para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de Capital Económico.']}, {'tag': 'Stress Testing', 'patterns': ['stress', 'estres'], 'responses': ['- Aplicación de Pruebas de Estrés a modelos de Valor en Riesgo de la Cartera de Inversiones y portafolio de Crédito. - Se proponen varias metodologías, para manejar indicadores en situaciónes adversas, del portafolio actual de la entidad.']}, {'tag': 'Machine Learning Admission', 'patterns': ['learning admission', 'originacion con inteligencia', 'admision con inteligencia', 'otorgamiento con inteligencia'], 'responses': ['- Modelo  para Otorgamiento de Préstamos, basado en  Machine Learning, para predecir la Probabilidad de Default de Prospectos a Cliente. - Tiende a Presentar Resultados Más Contundentes que los Modelos Clásicos, es decir, al poseer una capacidad de ajuste no lineal, las diferencias encontradas suelen representarse mejor en data real. - Se Testean y Entrenan contra indicadores robustos y ampliamente utilizados en el Sector Financiero para ajustes de Modelos, aplicables también a los Modelos Clásicos.- Permite trabajar con Segmentos No  Tradicionales.- Se entrenan en menor tiempo que los modelos clásicos.']}, {'tag': 'Risk Based Pricing', 'patterns': ['risk pricing', 'precios enfocado en riesgo', 'precios', 'pricing'], 'responses': ['- Modelo de Precios Basado en Riesgo, utiilizando Modelos Analíticos, en función de la Probabilidad de Default de Clientes en el Producto. - Permite mantener un margen financiero positivo, que sincera los costos asociados al default de productos observados. - Puede combinarse a otros Modelos Analíticos para realizar una asignación de Precios Dinámica,  que asocie el valor del cliente para la Institución, junto al riesgo que presenta su Patrón de Comportamiento  de Pago y Utilización de Productos.']}, {'tag': 'Prouct Recommender', 'patterns': ['prouct recommender', 'recomendar productos'], 'responses': ['- Modelo de Venta, basado en Inteligencia Artificial , permite Recomendar Productos a Clientes de Institución Financiera.- Es altamente utilizado por empresas como Amazon, Netflix, Youtube para realizar ofertas adecuadas a clientes basada en la utilización y valoración de productos.- En combinación con otros modelos , permite la activación de fabricas de originación de créditos.']}, {'tag': 'Acceptance Probability', 'patterns': ['acceptance', 'aceptacion'], 'responses': ['- Modelo de Venta, basado en Machine Learning para predecir la Probabilidad de Aceptación de la Oferta de Clientes- Permite reducción reducir el esfuerzo de ventas.- En combinación con los modelos adecuados, permite una focalización en clientes importantes para la Institución.']}, {'tag': 'Active Behaviour Model', 'patterns': ['active behaviour', 'activos'], 'responses': ['- Modelo Comportamental , Basado en Estadística Clásica para predecir la Probabilidad de Incumplimiento de  Clientes con historia en la Institución.- Es un Modelo con un Performance Alto , asímismo ,  también Muy Estable en el Tiempo- Permite Asignar tratamientos para ventas, fijar tasas, entre otras estrategias de uso comercial. Por cuanto, sirve como input para otros Modelos Analíticos.']}, {'tag': 'Fraud Payment Default', 'patterns': ['fraud', 'fraude'], 'responses': ['- Modelo de Prevención de Fraude , basado en Machine Learning para Predecir la Probabilidad de que el Prospecto ejecute  First , Second o Third Payment Default.- Utiliza indicadores de desempeńo bastante robustos, que permiten evaluar adecuadamente el evento de interés  (Detección de Candidatos con Intención de Incumplir con sus Facilidades crediticias)- Ayuda a Mejorar la Selección de Prospectos de los Modelos de Originación.']}, {'tag': 'Roll Rates', 'patterns': ['roll rates', 'matriz de transicion'], 'responses': ['- Preparación de Roll Rates, para estimar la de la Proababilidad de Default, bajo proyecciones de las transiciones de Mora.-  Forma parte de la Metodología de Basilea para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de  Capital Económico.']}, {'tag': 'Portfolio Classification', 'patterns': ['classification', 'clasificacion'], 'responses': ['- Modelo de Clasificación para Carterizar a Clientes Nuevos, que no participaron en la Segmentación base, o bien, para Refrescar los Segmentos de Clientes Existentes.- Este modelo replica la información contenida en los segmentos ya predefinidos en la institución para aplicársela a los clentes.- Se recomienda realizar corridas mensuales para mantener actualizada la cartera de la Institución.']}, {'tag': 'Portfolio Segmentation', 'patterns': ['segmentation', 'segmentacion'], 'responses': ['- Modelo para Segmentar el Portafolio de Crédito, basado en el Comportamiento de Clientes.- Este tipo de desarrollos, son altamente utilizados para definir nuevos segmentos de clientes y con ello, se establece un tratamiento y una estrategía de comercialización de productos, con el fin de optimizar los recursos , minimizando el esfuerzo de venta.- Es recomendable utilizar este producto en combinación con una clasificación de segmentos a posteriori, del mismo modo, se puede asociar con modelos de ventas cruzadas y mejoras de oferta.']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'Back-Test', 'patterns': ['back', 'retrospectivas', 'retrospectiva'], 'responses': ['- Aplicación de Back-Testing  a Modelos de estimación del Valor en Riesgo, para verificar su correcto ajuste a la Historia de la EIF.- Se recomienda Aplicar Backtest a cada Modelo propuesto.']}, {'tag': 'CLTV Based Pricing', 'patterns': ['cltv', 'lifetime'], 'responses': ['- Modelo de Precios en base al Valor del Cliente en el Tiempo, con un enfoque Estadístico Clásico - Comportamental, que persigue un ajuste del valor de cliente en función del retorno que genera hacia la Institución Financiera.- Funciona como complemento a la visión Riesgo Céntrica del Pricing. - Mediante la aplicación conjunta de los modelos de Pricing se consigue un ajuste Dinámico del Pricing.']}, {'tag': 'Atrittion Score', 'patterns': ['atrittion', 'atrittion'], 'responses': ['- Modelo de Retención, basado en Estadística Clásica, para predecir la Probabilidad de Deserción de Clientes.- Permite generar estrategías de retención en función de la probabilidad que presentan los prospectos para dejar de utilizar sus productos financieros.- En combinación con modelos de venta, originación y clasificación de portafolio, resulta muy efectivo para focalizar los esfuerzos en los clientes que realmente valgan la pena.']}, {'tag': 'Pasives Behaviour Model', 'patterns': ['pasives behaviour', 'pasivos', 'pasivo'], 'responses': ['- Modelo Comportamental, basado en Estadística Clásica, para predecir la Probabilidad de Incumplimiento de Clientes con productos en la Institución.- Tiene un Performance Alto, y presenta Mucha Estabilidad en el Tiempo , tal y como suelen tener sus homólogos basados en Productos Activos.-  Suelen combinarse con otros modelos comportamentales para dar una visión más completa del cliente.']}, {'tag': 'VaR Models', 'patterns': ['valor en riesgo', 'value at risk'], 'responses': ['- Modelos de Valor en Riesgo (Value At Risk) , con enfoque de  Estadística Clásica, para estimar el monto que se espera perder, bajo cierto nivel de certidumbre, en función de la composición del portafolio  estudiado.- Se proponen varios modelos de estudio, como indicadores de seguimiento de la cartera de Inversiones.-  Debe combinarse con Modelos de Pérdidas Esperadas.']}, {'tag': 'Collections Score', 'patterns': ['collections', 'collections', 'cobranzas'], 'responses': ['- Modelo de Cobranzas , basado en Estadística Clásica , para Administrar Tratamientos a Clientes con productos Activos en la Institución Financiera.   Pudiendo, acoplarse a los tratamientos de cobros impuestos por la EIF, pero con el aditivo preventivo  de los modelos que utiliza como base. - Resulta Altamente Eficaz en la prevención del deterioro de clientes con oportunidades de mejora, dado que establece tratamientos desde la premora.- Permite focalizar los esfuerzos  para mejorar su efectividad y eficientizar las labores del Área de Cobros.']}, {'tag': 'Crossell - Upsell Model', 'patterns': ['crossell upsell model', 'ventas cruzadas'], 'responses': ['- Modelo para Ventas Cruzadas, basado en Estadística Clásica, fundamentado en el Comportamiento  y uso de los productos Financieros de los Clientes.- En combinación de los modelos de Probabilidad de Aceptación de Oferta, Admisión , Pricing , Clasificación de Portafolio, permite focalizar los esfuerzos en clientes que generen mayor retorno para la Institución.']}, {'tag': 'Early Warnings', 'patterns': ['early warnings', 'alertas tempranas'], 'responses': ['- Modelo Comportamental aplicado a Cobranzas, basado en Estadística Clásica, para predecir la Probabilidad de Default de Clientes con Productos activos  en estado de Premora.- Sirve para imponer tratamientos preventivos efectivos ante clientes que presentan mayor probabilidad de incumplir con sus facilidades crediticia, pese a que, al momento de realizar el estudio se encuentran en premora.- Son ampliamente utilizados en el Sector Financiero, para asegurar la efectividad de la Cobranza, y suelen combinarse con otros modelos Comportamentales para generar estrategias adecuadas para cobro, bajo un Modelo de Cobranzas.']}, {'tag': 'Credit Admission Scores', 'patterns': ['credit admission', 'originacion', 'otorgamiento'], 'responses': ['- Modelo de Otorgamiento de Préstamos, basado en Estadística Clásica, para predecir la Probabilidad Default de Prospectos a Clientes.  - Es uno de los modelos más utilizados y reconocidos  internacionalmente  por su buen desempeño, simplicidad y resistencia al paso del tiempo.- Puede ser reacondicionado en el tiempo, a menos que haya sufrido un deterioro muy fuerte.- Sirve como punto de partida para estudios de Pricing , Especificaciones de Punto de Corte y Políticas.']}, {'tag': 'Loss Given By Default', 'patterns': ['loss given by default', 'lgd', 'perdidas_dado_incumplimiento'], 'responses': ['- Estimación de Pérdidas Financieras dado el Incumplimiento de Préstamos, en función de Modelos Estadísticos Clásicos.- Forma parte de la Metodología de Basilea, para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de Capital Económico.']}, {'tag': 'Stress Testing', 'patterns': ['stress', 'estres'], 'responses': ['- Aplicación de Pruebas de Estrés a modelos de Valor en Riesgo de la Cartera de Inversiones y portafolio de Crédito. - Se proponen varias metodologías, para manejar indicadores en situaciónes adversas, del portafolio actual de la entidad.']}, {'tag': 'Machine Learning Admission', 'patterns': ['learning admission', 'originacion con inteligencia', 'admision con inteligencia', 'otorgamiento con inteligencia'], 'responses': ['- Modelo  para Otorgamiento de Préstamos, basado en  Machine Learning, para predecir la Probabilidad de Default de Prospectos a Cliente. - Tiende a Presentar Resultados Más Contundentes que los Modelos Clásicos, es decir, al poseer una capacidad de ajuste no lineal, las diferencias encontradas suelen representarse mejor en data real. - Se Testean y Entrenan contra indicadores robustos y ampliamente utilizados en el Sector Financiero para ajustes de Modelos, aplicables también a los Modelos Clásicos.- Permite trabajar con Segmentos No  Tradicionales.- Se entrenan en menor tiempo que los modelos clásicos.']}, {'tag': 'Risk Based Pricing', 'patterns': ['risk pricing', 'precios enfocado en riesgo', 'precios', 'pricing'], 'responses': ['- Modelo de Precios Basado en Riesgo, utiilizando Modelos Analíticos, en función de la Probabilidad de Default de Clientes en el Producto. - Permite mantener un margen financiero positivo, que sincera los costos asociados al default de productos observados. - Puede combinarse a otros Modelos Analíticos para realizar una asignación de Precios Dinámica,  que asocie el valor del cliente para la Institución, junto al riesgo que presenta su Patrón de Comportamiento  de Pago y Utilización de Productos.']}, {'tag': 'Prouct Recommender', 'patterns': ['prouct recommender', 'recomendar productos'], 'responses': ['- Modelo de Venta, basado en Inteligencia Artificial , permite Recomendar Productos a Clientes de Institución Financiera.- Es altamente utilizado por empresas como Amazon, Netflix, Youtube para realizar ofertas adecuadas a clientes basada en la utilización y valoración de productos.- En combinación con otros modelos , permite la activación de fabricas de originación de créditos.']}, {'tag': 'Acceptance Probability', 'patterns': ['acceptance', 'aceptacion'], 'responses': ['- Modelo de Venta, basado en Machine Learning para predecir la Probabilidad de Aceptación de la Oferta de Clientes- Permite reducción reducir el esfuerzo de ventas.- En combinación con los modelos adecuados, permite una focalización en clientes importantes para la Institución.']}, {'tag': 'Active Behaviour Model', 'patterns': ['active behaviour', 'activos'], 'responses': ['- Modelo Comportamental , Basado en Estadística Clásica para predecir la Probabilidad de Incumplimiento de  Clientes con historia en la Institución.- Es un Modelo con un Performance Alto , asímismo ,  también Muy Estable en el Tiempo- Permite Asignar tratamientos para ventas, fijar tasas, entre otras estrategias de uso comercial. Por cuanto, sirve como input para otros Modelos Analíticos.']}, {'tag': 'Fraud Payment Default', 'patterns': ['fraud', 'fraude'], 'responses': ['- Modelo de Prevención de Fraude , basado en Machine Learning para Predecir la Probabilidad de que el Prospecto ejecute  First , Second o Third Payment Default.- Utiliza indicadores de desempeńo bastante robustos, que permiten evaluar adecuadamente el evento de interés  (Detección de Candidatos con Intención de Incumplir con sus Facilidades crediticias)- Ayuda a Mejorar la Selección de Prospectos de los Modelos de Originación.']}, {'tag': 'Roll Rates', 'patterns': ['roll rates', 'matriz de transicion'], 'responses': ['- Preparación de Roll Rates, para estimar la de la Proababilidad de Default, bajo proyecciones de las transiciones de Mora.-  Forma parte de la Metodología de Basilea para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de  Capital Económico.']}, {'tag': 'Portfolio Classification', 'patterns': ['classification', 'clasificacion'], 'responses': ['- Modelo de Clasificación para Carterizar a Clientes Nuevos, que no participaron en la Segmentación base, o bien, para Refrescar los Segmentos de Clientes Existentes.- Este modelo replica la información contenida en los segmentos ya predefinidos en la institución para aplicársela a los clentes.- Se recomienda realizar corridas mensuales para mantener actualizada la cartera de la Institución.']}, {'tag': 'Portfolio Segmentation', 'patterns': ['segmentation', 'segmentacion'], 'responses': ['- Modelo para Segmentar el Portafolio de Crédito, basado en el Comportamiento de Clientes.- Este tipo de desarrollos, son altamente utilizados para definir nuevos segmentos de clientes y con ello, se establece un tratamiento y una estrategía de comercialización de productos, con el fin de optimizar los recursos , minimizando el esfuerzo de venta.- Es recomendable utilizar este producto en combinación con una clasificación de segmentos a posteriori, del mismo modo, se puede asociar con modelos de ventas cruzadas y mejoras de oferta.']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag': 'Back-Test', 'patterns': ['back', 'retrospectivas', 'retrospectiva'], 'responses': ['- Aplicación de Back-Testing  a Modelos de estimación del Valor en Riesgo, para verificar su correcto ajuste a la Historia de la EIF.- Se recomienda Aplicar Backtest a cada Modelo propuesto.']}\n",
      "{'tag': 'CLTV Based Pricing', 'patterns': ['cltv', 'lifetime'], 'responses': ['- Modelo de Precios en base al Valor del Cliente en el Tiempo, con un enfoque Estadístico Clásico - Comportamental, que persigue un ajuste del valor de cliente en función del retorno que genera hacia la Institución Financiera.- Funciona como complemento a la visión Riesgo Céntrica del Pricing. - Mediante la aplicación conjunta de los modelos de Pricing se consigue un ajuste Dinámico del Pricing.']}\n",
      "{'tag': 'Atrittion Score', 'patterns': ['atrittion', 'atrittion'], 'responses': ['- Modelo de Retención, basado en Estadística Clásica, para predecir la Probabilidad de Deserción de Clientes.- Permite generar estrategías de retención en función de la probabilidad que presentan los prospectos para dejar de utilizar sus productos financieros.- En combinación con modelos de venta, originación y clasificación de portafolio, resulta muy efectivo para focalizar los esfuerzos en los clientes que realmente valgan la pena.']}\n",
      "{'tag': 'Pasives Behaviour Model', 'patterns': ['pasives behaviour', 'pasivos', 'pasivo'], 'responses': ['- Modelo Comportamental, basado en Estadística Clásica, para predecir la Probabilidad de Incumplimiento de Clientes con productos en la Institución.- Tiene un Performance Alto, y presenta Mucha Estabilidad en el Tiempo , tal y como suelen tener sus homólogos basados en Productos Activos.-  Suelen combinarse con otros modelos comportamentales para dar una visión más completa del cliente.']}\n",
      "{'tag': 'VaR Models', 'patterns': ['valor en riesgo', 'value at risk'], 'responses': ['- Modelos de Valor en Riesgo (Value At Risk) , con enfoque de  Estadística Clásica, para estimar el monto que se espera perder, bajo cierto nivel de certidumbre, en función de la composición del portafolio  estudiado.- Se proponen varios modelos de estudio, como indicadores de seguimiento de la cartera de Inversiones.-  Debe combinarse con Modelos de Pérdidas Esperadas.']}\n",
      "{'tag': 'Collections Score', 'patterns': ['collections', 'collections', 'cobranzas'], 'responses': ['- Modelo de Cobranzas , basado en Estadística Clásica , para Administrar Tratamientos a Clientes con productos Activos en la Institución Financiera.   Pudiendo, acoplarse a los tratamientos de cobros impuestos por la EIF, pero con el aditivo preventivo  de los modelos que utiliza como base. - Resulta Altamente Eficaz en la prevención del deterioro de clientes con oportunidades de mejora, dado que establece tratamientos desde la premora.- Permite focalizar los esfuerzos  para mejorar su efectividad y eficientizar las labores del Área de Cobros.']}\n",
      "{'tag': 'Crossell - Upsell Model', 'patterns': ['crossell upsell model', 'ventas cruzadas'], 'responses': ['- Modelo para Ventas Cruzadas, basado en Estadística Clásica, fundamentado en el Comportamiento  y uso de los productos Financieros de los Clientes.- En combinación de los modelos de Probabilidad de Aceptación de Oferta, Admisión , Pricing , Clasificación de Portafolio, permite focalizar los esfuerzos en clientes que generen mayor retorno para la Institución.']}\n",
      "{'tag': 'Early Warnings', 'patterns': ['early warnings', 'alertas tempranas'], 'responses': ['- Modelo Comportamental aplicado a Cobranzas, basado en Estadística Clásica, para predecir la Probabilidad de Default de Clientes con Productos activos  en estado de Premora.- Sirve para imponer tratamientos preventivos efectivos ante clientes que presentan mayor probabilidad de incumplir con sus facilidades crediticia, pese a que, al momento de realizar el estudio se encuentran en premora.- Son ampliamente utilizados en el Sector Financiero, para asegurar la efectividad de la Cobranza, y suelen combinarse con otros modelos Comportamentales para generar estrategias adecuadas para cobro, bajo un Modelo de Cobranzas.']}\n",
      "{'tag': 'Credit Admission Scores', 'patterns': ['credit admission', 'originacion', 'otorgamiento'], 'responses': ['- Modelo de Otorgamiento de Préstamos, basado en Estadística Clásica, para predecir la Probabilidad Default de Prospectos a Clientes.  - Es uno de los modelos más utilizados y reconocidos  internacionalmente  por su buen desempeño, simplicidad y resistencia al paso del tiempo.- Puede ser reacondicionado en el tiempo, a menos que haya sufrido un deterioro muy fuerte.- Sirve como punto de partida para estudios de Pricing , Especificaciones de Punto de Corte y Políticas.']}\n",
      "{'tag': 'Loss Given By Default', 'patterns': ['loss given by default', 'lgd', 'perdidas_dado_incumplimiento'], 'responses': ['- Estimación de Pérdidas Financieras dado el Incumplimiento de Préstamos, en función de Modelos Estadísticos Clásicos.- Forma parte de la Metodología de Basilea, para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de Capital Económico.']}\n",
      "{'tag': 'Stress Testing', 'patterns': ['stress', 'estres'], 'responses': ['- Aplicación de Pruebas de Estrés a modelos de Valor en Riesgo de la Cartera de Inversiones y portafolio de Crédito. - Se proponen varias metodologías, para manejar indicadores en situaciónes adversas, del portafolio actual de la entidad.']}\n",
      "{'tag': 'Machine Learning Admission', 'patterns': ['learning admission', 'originacion con inteligencia', 'admision con inteligencia', 'otorgamiento con inteligencia'], 'responses': ['- Modelo  para Otorgamiento de Préstamos, basado en  Machine Learning, para predecir la Probabilidad de Default de Prospectos a Cliente. - Tiende a Presentar Resultados Más Contundentes que los Modelos Clásicos, es decir, al poseer una capacidad de ajuste no lineal, las diferencias encontradas suelen representarse mejor en data real. - Se Testean y Entrenan contra indicadores robustos y ampliamente utilizados en el Sector Financiero para ajustes de Modelos, aplicables también a los Modelos Clásicos.- Permite trabajar con Segmentos No  Tradicionales.- Se entrenan en menor tiempo que los modelos clásicos.']}\n",
      "{'tag': 'Risk Based Pricing', 'patterns': ['risk pricing', 'precios enfocado en riesgo', 'precios', 'pricing'], 'responses': ['- Modelo de Precios Basado en Riesgo, utiilizando Modelos Analíticos, en función de la Probabilidad de Default de Clientes en el Producto. - Permite mantener un margen financiero positivo, que sincera los costos asociados al default de productos observados. - Puede combinarse a otros Modelos Analíticos para realizar una asignación de Precios Dinámica,  que asocie el valor del cliente para la Institución, junto al riesgo que presenta su Patrón de Comportamiento  de Pago y Utilización de Productos.']}\n",
      "{'tag': 'Prouct Recommender', 'patterns': ['prouct recommender', 'recomendar productos'], 'responses': ['- Modelo de Venta, basado en Inteligencia Artificial , permite Recomendar Productos a Clientes de Institución Financiera.- Es altamente utilizado por empresas como Amazon, Netflix, Youtube para realizar ofertas adecuadas a clientes basada en la utilización y valoración de productos.- En combinación con otros modelos , permite la activación de fabricas de originación de créditos.']}\n",
      "{'tag': 'Acceptance Probability', 'patterns': ['acceptance', 'aceptacion'], 'responses': ['- Modelo de Venta, basado en Machine Learning para predecir la Probabilidad de Aceptación de la Oferta de Clientes- Permite reducción reducir el esfuerzo de ventas.- En combinación con los modelos adecuados, permite una focalización en clientes importantes para la Institución.']}\n",
      "{'tag': 'Active Behaviour Model', 'patterns': ['active behaviour', 'activos'], 'responses': ['- Modelo Comportamental , Basado en Estadística Clásica para predecir la Probabilidad de Incumplimiento de  Clientes con historia en la Institución.- Es un Modelo con un Performance Alto , asímismo ,  también Muy Estable en el Tiempo- Permite Asignar tratamientos para ventas, fijar tasas, entre otras estrategias de uso comercial. Por cuanto, sirve como input para otros Modelos Analíticos.']}\n",
      "{'tag': 'Fraud Payment Default', 'patterns': ['fraud', 'fraude'], 'responses': ['- Modelo de Prevención de Fraude , basado en Machine Learning para Predecir la Probabilidad de que el Prospecto ejecute  First , Second o Third Payment Default.- Utiliza indicadores de desempeńo bastante robustos, que permiten evaluar adecuadamente el evento de interés  (Detección de Candidatos con Intención de Incumplir con sus Facilidades crediticias)- Ayuda a Mejorar la Selección de Prospectos de los Modelos de Originación.']}\n",
      "{'tag': 'Roll Rates', 'patterns': ['roll rates', 'matriz de transicion'], 'responses': ['- Preparación de Roll Rates, para estimar la de la Proababilidad de Default, bajo proyecciones de las transiciones de Mora.-  Forma parte de la Metodología de Basilea para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de  Capital Económico.']}\n",
      "{'tag': 'Portfolio Classification', 'patterns': ['classification', 'clasificacion'], 'responses': ['- Modelo de Clasificación para Carterizar a Clientes Nuevos, que no participaron en la Segmentación base, o bien, para Refrescar los Segmentos de Clientes Existentes.- Este modelo replica la información contenida en los segmentos ya predefinidos en la institución para aplicársela a los clentes.- Se recomienda realizar corridas mensuales para mantener actualizada la cartera de la Institución.']}\n",
      "{'tag': 'Portfolio Segmentation', 'patterns': ['segmentation', 'segmentacion'], 'responses': ['- Modelo para Segmentar el Portafolio de Crédito, basado en el Comportamiento de Clientes.- Este tipo de desarrollos, son altamente utilizados para definir nuevos segmentos de clientes y con ello, se establece un tratamiento y una estrategía de comercialización de productos, con el fin de optimizar los recursos , minimizando el esfuerzo de venta.- Es recomendable utilizar este producto en combinación con una clasificación de segmentos a posteriori, del mismo modo, se puede asociar con modelos de ventas cruzadas y mejoras de oferta.']}\n"
     ]
    }
   ],
   "source": [
    "# dict_base={}\n",
    "# contador = 0\n",
    "# for i in intents['intents']:\n",
    "\n",
    "#     revision_data=i[1:len(i)-1].split(\":\")\n",
    "#     # print(revision_data)\n",
    "#     # print(revision_data[1].split(\",\")[0])\n",
    "#     # print(revision_data[1].split(\",\")[1])\n",
    "#     cut0=revision_data[0]\n",
    "#     cut1=(revision_data[1].split(\",\")[1])\n",
    "#     cut2=(revision_data[2].split(\"],\")[1])\n",
    "\n",
    "#     print( (cut0,cut1,cut2))\n",
    "#     data1=(revision_data[1].split(\",\")[0])\n",
    "#     data2=(revision_data[2].split(\"],\")[0])\n",
    "#     data3=(revision_data[3])\n",
    "#     print((data1,data2,data3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # for j in range(len(revision_data)):\n",
    "#     #     if (j%2==0):\n",
    "#     #         print(revision_data[j])\n",
    "#     #         # if (contador == 0):\n",
    "#     #         dict_base[revision_data[j]] = revision_data[(j+1)]\n",
    "#             # else :\n",
    "#             #     dict_base[revision_data[j]]  revision_data[(j+1)]\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    print(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'Back-Test',\n",
       "  'patterns': ['back', 'retrospectivas', 'retrospectiva'],\n",
       "  'responses': ['- Aplicación de Back-Testing  a Modelos de estimación del Valor en Riesgo, para verificar su correcto ajuste a la Historia de la EIF.- Se recomienda Aplicar Backtest a cada Modelo propuesto.']},\n",
       " {'tag': 'CLTV Based Pricing',\n",
       "  'patterns': ['cltv', 'lifetime'],\n",
       "  'responses': ['- Modelo de Precios en base al Valor del Cliente en el Tiempo, con un enfoque Estadístico Clásico - Comportamental, que persigue un ajuste del valor de cliente en función del retorno que genera hacia la Institución Financiera.- Funciona como complemento a la visión Riesgo Céntrica del Pricing. - Mediante la aplicación conjunta de los modelos de Pricing se consigue un ajuste Dinámico del Pricing.']},\n",
       " {'tag': 'Atrittion Score',\n",
       "  'patterns': ['atrittion', 'atrittion'],\n",
       "  'responses': ['- Modelo de Retención, basado en Estadística Clásica, para predecir la Probabilidad de Deserción de Clientes.- Permite generar estrategías de retención en función de la probabilidad que presentan los prospectos para dejar de utilizar sus productos financieros.- En combinación con modelos de venta, originación y clasificación de portafolio, resulta muy efectivo para focalizar los esfuerzos en los clientes que realmente valgan la pena.']},\n",
       " {'tag': 'Pasives Behaviour Model',\n",
       "  'patterns': ['pasives behaviour', 'pasivos', 'pasivo'],\n",
       "  'responses': ['- Modelo Comportamental, basado en Estadística Clásica, para predecir la Probabilidad de Incumplimiento de Clientes con productos en la Institución.- Tiene un Performance Alto, y presenta Mucha Estabilidad en el Tiempo , tal y como suelen tener sus homólogos basados en Productos Activos.-  Suelen combinarse con otros modelos comportamentales para dar una visión más completa del cliente.']},\n",
       " {'tag': 'VaR Models',\n",
       "  'patterns': ['valor en riesgo', 'value at risk'],\n",
       "  'responses': ['- Modelos de Valor en Riesgo (Value At Risk) , con enfoque de  Estadística Clásica, para estimar el monto que se espera perder, bajo cierto nivel de certidumbre, en función de la composición del portafolio  estudiado.- Se proponen varios modelos de estudio, como indicadores de seguimiento de la cartera de Inversiones.-  Debe combinarse con Modelos de Pérdidas Esperadas.']},\n",
       " {'tag': 'Collections Score',\n",
       "  'patterns': ['collections', 'collections', 'cobranzas'],\n",
       "  'responses': ['- Modelo de Cobranzas , basado en Estadística Clásica , para Administrar Tratamientos a Clientes con productos Activos en la Institución Financiera.   Pudiendo, acoplarse a los tratamientos de cobros impuestos por la EIF, pero con el aditivo preventivo  de los modelos que utiliza como base. - Resulta Altamente Eficaz en la prevención del deterioro de clientes con oportunidades de mejora, dado que establece tratamientos desde la premora.- Permite focalizar los esfuerzos  para mejorar su efectividad y eficientizar las labores del Área de Cobros.']},\n",
       " {'tag': 'Crossell - Upsell Model',\n",
       "  'patterns': ['crossell upsell model', 'ventas cruzadas'],\n",
       "  'responses': ['- Modelo para Ventas Cruzadas, basado en Estadística Clásica, fundamentado en el Comportamiento  y uso de los productos Financieros de los Clientes.- En combinación de los modelos de Probabilidad de Aceptación de Oferta, Admisión , Pricing , Clasificación de Portafolio, permite focalizar los esfuerzos en clientes que generen mayor retorno para la Institución.']},\n",
       " {'tag': 'Early Warnings',\n",
       "  'patterns': ['early warnings', 'alertas tempranas'],\n",
       "  'responses': ['- Modelo Comportamental aplicado a Cobranzas, basado en Estadística Clásica, para predecir la Probabilidad de Default de Clientes con Productos activos  en estado de Premora.- Sirve para imponer tratamientos preventivos efectivos ante clientes que presentan mayor probabilidad de incumplir con sus facilidades crediticia, pese a que, al momento de realizar el estudio se encuentran en premora.- Son ampliamente utilizados en el Sector Financiero, para asegurar la efectividad de la Cobranza, y suelen combinarse con otros modelos Comportamentales para generar estrategias adecuadas para cobro, bajo un Modelo de Cobranzas.']},\n",
       " {'tag': 'Credit Admission Scores',\n",
       "  'patterns': ['credit admission', 'originacion', 'otorgamiento'],\n",
       "  'responses': ['- Modelo de Otorgamiento de Préstamos, basado en Estadística Clásica, para predecir la Probabilidad Default de Prospectos a Clientes.  - Es uno de los modelos más utilizados y reconocidos  internacionalmente  por su buen desempeño, simplicidad y resistencia al paso del tiempo.- Puede ser reacondicionado en el tiempo, a menos que haya sufrido un deterioro muy fuerte.- Sirve como punto de partida para estudios de Pricing , Especificaciones de Punto de Corte y Políticas.']},\n",
       " {'tag': 'Loss Given By Default',\n",
       "  'patterns': ['loss given by default', 'lgd', 'perdidas_dado_incumplimiento'],\n",
       "  'responses': ['- Estimación de Pérdidas Financieras dado el Incumplimiento de Préstamos, en función de Modelos Estadísticos Clásicos.- Forma parte de la Metodología de Basilea, para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de Capital Económico.']},\n",
       " {'tag': 'Stress Testing',\n",
       "  'patterns': ['stress', 'estres'],\n",
       "  'responses': ['- Aplicación de Pruebas de Estrés a modelos de Valor en Riesgo de la Cartera de Inversiones y portafolio de Crédito. - Se proponen varias metodologías, para manejar indicadores en situaciónes adversas, del portafolio actual de la entidad.']},\n",
       " {'tag': 'Machine Learning Admission',\n",
       "  'patterns': ['learning admission',\n",
       "   'originacion con inteligencia',\n",
       "   'admision con inteligencia',\n",
       "   'otorgamiento con inteligencia'],\n",
       "  'responses': ['- Modelo  para Otorgamiento de Préstamos, basado en  Machine Learning, para predecir la Probabilidad de Default de Prospectos a Cliente. - Tiende a Presentar Resultados Más Contundentes que los Modelos Clásicos, es decir, al poseer una capacidad de ajuste no lineal, las diferencias encontradas suelen representarse mejor en data real. - Se Testean y Entrenan contra indicadores robustos y ampliamente utilizados en el Sector Financiero para ajustes de Modelos, aplicables también a los Modelos Clásicos.- Permite trabajar con Segmentos No  Tradicionales.- Se entrenan en menor tiempo que los modelos clásicos.']},\n",
       " {'tag': 'Risk Based Pricing',\n",
       "  'patterns': ['risk pricing',\n",
       "   'precios enfocado en riesgo',\n",
       "   'precios',\n",
       "   'pricing'],\n",
       "  'responses': ['- Modelo de Precios Basado en Riesgo, utiilizando Modelos Analíticos, en función de la Probabilidad de Default de Clientes en el Producto. - Permite mantener un margen financiero positivo, que sincera los costos asociados al default de productos observados. - Puede combinarse a otros Modelos Analíticos para realizar una asignación de Precios Dinámica,  que asocie el valor del cliente para la Institución, junto al riesgo que presenta su Patrón de Comportamiento  de Pago y Utilización de Productos.']},\n",
       " {'tag': 'Prouct Recommender',\n",
       "  'patterns': ['prouct recommender', 'recomendar productos'],\n",
       "  'responses': ['- Modelo de Venta, basado en Inteligencia Artificial , permite Recomendar Productos a Clientes de Institución Financiera.- Es altamente utilizado por empresas como Amazon, Netflix, Youtube para realizar ofertas adecuadas a clientes basada en la utilización y valoración de productos.- En combinación con otros modelos , permite la activación de fabricas de originación de créditos.']},\n",
       " {'tag': 'Acceptance Probability',\n",
       "  'patterns': ['acceptance', 'aceptacion'],\n",
       "  'responses': ['- Modelo de Venta, basado en Machine Learning para predecir la Probabilidad de Aceptación de la Oferta de Clientes- Permite reducción reducir el esfuerzo de ventas.- En combinación con los modelos adecuados, permite una focalización en clientes importantes para la Institución.']},\n",
       " {'tag': 'Active Behaviour Model',\n",
       "  'patterns': ['active behaviour', 'activos'],\n",
       "  'responses': ['- Modelo Comportamental , Basado en Estadística Clásica para predecir la Probabilidad de Incumplimiento de  Clientes con historia en la Institución.- Es un Modelo con un Performance Alto , asímismo ,  también Muy Estable en el Tiempo- Permite Asignar tratamientos para ventas, fijar tasas, entre otras estrategias de uso comercial. Por cuanto, sirve como input para otros Modelos Analíticos.']},\n",
       " {'tag': 'Fraud Payment Default',\n",
       "  'patterns': ['fraud', 'fraude'],\n",
       "  'responses': ['- Modelo de Prevención de Fraude , basado en Machine Learning para Predecir la Probabilidad de que el Prospecto ejecute  First , Second o Third Payment Default.- Utiliza indicadores de desempeńo bastante robustos, que permiten evaluar adecuadamente el evento de interés  (Detección de Candidatos con Intención de Incumplir con sus Facilidades crediticias)- Ayuda a Mejorar la Selección de Prospectos de los Modelos de Originación.']},\n",
       " {'tag': 'Roll Rates',\n",
       "  'patterns': ['roll rates', 'matriz de transicion'],\n",
       "  'responses': ['- Preparación de Roll Rates, para estimar la de la Proababilidad de Default, bajo proyecciones de las transiciones de Mora.-  Forma parte de la Metodología de Basilea para Cálculo de Pérdidas Esperadas y su consecuente requerimiento de  Capital Económico.']},\n",
       " {'tag': 'Portfolio Classification',\n",
       "  'patterns': ['classification', 'clasificacion'],\n",
       "  'responses': ['- Modelo de Clasificación para Carterizar a Clientes Nuevos, que no participaron en la Segmentación base, o bien, para Refrescar los Segmentos de Clientes Existentes.- Este modelo replica la información contenida en los segmentos ya predefinidos en la institución para aplicársela a los clentes.- Se recomienda realizar corridas mensuales para mantener actualizada la cartera de la Institución.']},\n",
       " {'tag': 'Portfolio Segmentation',\n",
       "  'patterns': ['segmentation', 'segmentacion'],\n",
       "  'responses': ['- Modelo para Segmentar el Portafolio de Crédito, basado en el Comportamiento de Clientes.- Este tipo de desarrollos, son altamente utilizados para definir nuevos segmentos de clientes y con ello, se establece un tratamiento y una estrategía de comercialización de productos, con el fin de optimizar los recursos , minimizando el esfuerzo de venta.- Es recomendable utilizar este producto en combinación con una clasificación de segmentos a posteriori, del mismo modo, se puede asociar con modelos de ventas cruzadas y mejoras de oferta.']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents['intents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "clases=[]\n",
    "documents=[]\n",
    "ignore_letters=[\"?\",\"¿\",\"!\",\"¡\",\".\",\"-\",\"_\",\",\"]\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list=nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        documents.append(((word_list),intent['tag']))\n",
    "\n",
    "\n",
    "        if intent['tag'] not in clases:\n",
    "            clases.append(intent['tag'])\n",
    "\n",
    "words = [lemmantizer.lemmatize(word) for word in words \n",
    "       if not word in ignore_letters]\n",
    "\n",
    "words = sorted( set(words))\n",
    "\n",
    "\n",
    "pickle.dump(words, open('words_chatbot_productos.pkl','wb'))\n",
    "pickle.dump(clases, open('clases_chatbot_productos.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['back'], 'Back-Test'),\n",
       " (['retrospectivas'], 'Back-Test'),\n",
       " (['retrospectiva'], 'Back-Test'),\n",
       " (['cltv'], 'CLTV Based Pricing'),\n",
       " (['lifetime'], 'CLTV Based Pricing'),\n",
       " (['atrittion'], 'Atrittion Score'),\n",
       " (['atrittion'], 'Atrittion Score'),\n",
       " (['pasives', 'behaviour'], 'Pasives Behaviour Model'),\n",
       " (['pasivos'], 'Pasives Behaviour Model'),\n",
       " (['pasivo'], 'Pasives Behaviour Model'),\n",
       " (['valor', 'en', 'riesgo'], 'VaR Models'),\n",
       " (['value', 'at', 'risk'], 'VaR Models'),\n",
       " (['collections'], 'Collections Score'),\n",
       " (['collections'], 'Collections Score'),\n",
       " (['cobranzas'], 'Collections Score'),\n",
       " (['crossell', 'upsell', 'model'], 'Crossell - Upsell Model'),\n",
       " (['ventas', 'cruzadas'], 'Crossell - Upsell Model'),\n",
       " (['early', 'warnings'], 'Early Warnings'),\n",
       " (['alertas', 'tempranas'], 'Early Warnings'),\n",
       " (['credit', 'admission'], 'Credit Admission Scores'),\n",
       " (['originacion'], 'Credit Admission Scores'),\n",
       " (['otorgamiento'], 'Credit Admission Scores'),\n",
       " (['loss', 'given', 'by', 'default'], 'Loss Given By Default'),\n",
       " (['lgd'], 'Loss Given By Default'),\n",
       " (['perdidas_dado_incumplimiento'], 'Loss Given By Default'),\n",
       " (['stress'], 'Stress Testing'),\n",
       " (['estres'], 'Stress Testing'),\n",
       " (['learning', 'admission'], 'Machine Learning Admission'),\n",
       " (['originacion', 'con', 'inteligencia'], 'Machine Learning Admission'),\n",
       " (['admision', 'con', 'inteligencia'], 'Machine Learning Admission'),\n",
       " (['otorgamiento', 'con', 'inteligencia'], 'Machine Learning Admission'),\n",
       " (['risk', 'pricing'], 'Risk Based Pricing'),\n",
       " (['precios', 'enfocado', 'en', 'riesgo'], 'Risk Based Pricing'),\n",
       " (['precios'], 'Risk Based Pricing'),\n",
       " (['pricing'], 'Risk Based Pricing'),\n",
       " (['prouct', 'recommender'], 'Prouct Recommender'),\n",
       " (['recomendar', 'productos'], 'Prouct Recommender'),\n",
       " (['acceptance'], 'Acceptance Probability'),\n",
       " (['aceptacion'], 'Acceptance Probability'),\n",
       " (['active', 'behaviour'], 'Active Behaviour Model'),\n",
       " (['activos'], 'Active Behaviour Model'),\n",
       " (['fraud'], 'Fraud Payment Default'),\n",
       " (['fraude'], 'Fraud Payment Default'),\n",
       " (['roll', 'rates'], 'Roll Rates'),\n",
       " (['matriz', 'de', 'transicion'], 'Roll Rates'),\n",
       " (['classification'], 'Portfolio Classification'),\n",
       " (['clasificacion'], 'Portfolio Classification'),\n",
       " (['segmentation'], 'Portfolio Segmentation'),\n",
       " (['segmentacion'], 'Portfolio Segmentation')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acceptance',\n",
       " 'aceptacion',\n",
       " 'active',\n",
       " 'activos',\n",
       " 'admision',\n",
       " 'admission',\n",
       " 'alertas',\n",
       " 'at',\n",
       " 'atrittion',\n",
       " 'back',\n",
       " 'behaviour',\n",
       " 'by',\n",
       " 'clasificacion',\n",
       " 'classification',\n",
       " 'cltv',\n",
       " 'cobranzas',\n",
       " 'collection',\n",
       " 'con',\n",
       " 'credit',\n",
       " 'crossell',\n",
       " 'cruzadas',\n",
       " 'de',\n",
       " 'default',\n",
       " 'early',\n",
       " 'en',\n",
       " 'enfocado',\n",
       " 'estres',\n",
       " 'fraud',\n",
       " 'fraude',\n",
       " 'given',\n",
       " 'inteligencia',\n",
       " 'learning',\n",
       " 'lgd',\n",
       " 'lifetime',\n",
       " 'loss',\n",
       " 'matriz',\n",
       " 'model',\n",
       " 'originacion',\n",
       " 'otorgamiento',\n",
       " 'pasives',\n",
       " 'pasivo',\n",
       " 'pasivos',\n",
       " 'perdidas_dado_incumplimiento',\n",
       " 'precios',\n",
       " 'pricing',\n",
       " 'productos',\n",
       " 'prouct',\n",
       " 'rate',\n",
       " 'recomendar',\n",
       " 'recommender',\n",
       " 'retrospectiva',\n",
       " 'retrospectivas',\n",
       " 'riesgo',\n",
       " 'risk',\n",
       " 'roll',\n",
       " 'segmentacion',\n",
       " 'segmentation',\n",
       " 'stress',\n",
       " 'tempranas',\n",
       " 'transicion',\n",
       " 'upsell',\n",
       " 'valor',\n",
       " 'value',\n",
       " 'ventas',\n",
       " 'warning']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Back-Test',\n",
       " 'CLTV Based Pricing',\n",
       " 'Atrittion Score',\n",
       " 'Pasives Behaviour Model',\n",
       " 'VaR Models',\n",
       " 'Collections Score',\n",
       " 'Crossell - Upsell Model',\n",
       " 'Early Warnings',\n",
       " 'Credit Admission Scores',\n",
       " 'Loss Given By Default',\n",
       " 'Stress Testing',\n",
       " 'Machine Learning Admission',\n",
       " 'Risk Based Pricing',\n",
       " 'Prouct Recommender',\n",
       " 'Acceptance Probability',\n",
       " 'Active Behaviour Model',\n",
       " 'Fraud Payment Default',\n",
       " 'Roll Rates',\n",
       " 'Portfolio Classification',\n",
       " 'Portfolio Segmentation']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\KMSpico\\temp\\ipykernel_15808\\3846777110.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training= np.array(training)\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding \n",
    "\n",
    "\n",
    "training=[]\n",
    "output_empty=[0]*len(clases)\n",
    "\n",
    "for document in documents:\n",
    "    bag=[]\n",
    "    word_patterns = document[0]\n",
    "    word_patterns = [lemmantizer.lemmatize((unidecode.unidecode(word)).lower()) for word in word_patterns]\n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_patterns else bag.append(0)\n",
    "    \n",
    "\n",
    "    output_row = list(output_empty) #making a copy of output_empty\n",
    "    output_row[clases.index(document[1])] = 1\n",
    "    training.append([bag,output_row])\n",
    "random.shuffle(training)\n",
    "training= np.array(training)\n",
    "\n",
    "\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot_trainer(tf.keras.Model):\n",
    "    def __init__(self,num_classes,activation='relu',units=128,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.num_classes=num_classes\n",
    "        # self.inputs=tf.keras.Input(shape=(26,))\n",
    "        self.flat=tf.keras.layers.Flatten()        \n",
    "        # self.dense0=tf.keras.layers.Dense(2*units,activation=activation)\n",
    "        # self.dropout0=tf.keras.layers.Dropout(0.5)\n",
    "        self.dense1=tf.keras.layers.Dense(units,activation=activation)\n",
    "        self.dropout1=tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2=tf.keras.layers.Dense((units/2), activation=activation)\n",
    "        self.dropout2=tf.keras.layers.Dropout(0.5)\n",
    "        self.dense3=tf.keras.layers.Dense(self.num_classes, activation='softmax')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        # input=self.input_base(input_shape=(len(input_length[0]),))\n",
    "        # input1=self.inputs()\n",
    "        x = self.flat(inputs)\n",
    "        # x = self.dense0(x)\n",
    "        # x = self.dropout0(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        output = self.dense3(x)\n",
    "\n",
    "        return  output\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    model=Chatbot_trainer(num_classes=np.array(train_y).shape[1])\n",
    "    # model.compile(optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=0.01,weight_decay=1e-6,momentum=0.90,nesterov=True),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    model.compile(optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=0.02,weight_decay=1e-6,momentum=0.9,nesterov=True),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['AUC'])\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.02,weight_decay=1e-6),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=tf.keras.metrics.Accuracy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device(\"/CPU:0\"):\n",
    "\n",
    "#    hist=model.fit(np.array(train_x), np.array(train_y),\n",
    "#                    epochs=3000, batch_size=5, verbose=1,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tf_train_y=tf.data.Dataset.from_tensor_slices(np.array(train_y))\n",
    "# model.fit(tf_train_x,tf_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('Chatbot_base_chatbot_producto_v2.tf'\n",
    "                                    \n",
    "                                     )\n",
    "\n",
    "# model2=Chatbot_trainer(num_classes=np.array(train_y).shape[1])\n",
    "#model2.compile(optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=0.02,weight_decay=1e-6,momentum=0.9,nesterov=True),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                    epochs=3000, batch_size=5, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in model2:\n",
    "#    print (i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.fit(np.array(train_x), np.array(train_y),\n",
    "#                    epochs=3000, batch_size=5, verbose=1,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"chatbot_trainer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  8448      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,004\n",
      "Trainable params: 18,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x274f1224220>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_weights('Chatbot_base_chatbot_producto_v2.tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flatten': <keras.layers.reshaping.flatten.Flatten object at 0x00000274EC56C550>, 'dense': <keras.layers.core.dense.Dense object at 0x00000274EC5A09A0>, 'dropout': <keras.layers.regularization.dropout.Dropout object at 0x00000274A4A6F190>, 'dense_1': <keras.layers.core.dense.Dense object at 0x00000274EA46F760>, 'dropout_1': <keras.layers.regularization.dropout.Dropout object at 0x00000274EE30E400>, 'dense_2': <keras.layers.core.dense.Dense object at 0x00000274EE30E6A0>}\n"
     ]
    }
   ],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model2.layers])\n",
    "print(layer_dict)\n",
    "model2.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.020230770111084, 0.5141059756278992]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_on_batch(np.array(train_x), np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten\n",
      "dense\n",
      "dropout\n",
      "dense_1\n",
      "dropout_1\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "for layers in model.layers:\n",
    "    layer_name=layers.name\n",
    "    print(layer_name)\n",
    "    layers.set_weights(layer_dict[layer_name].get_weights()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0020272731781006, 0.5022249221801758]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5802 - auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model.evaluate(np.array(train_x)[len(train_x)-4:len(train_x)-1],np.array(train_y)[len(train_x)-4:len(train_x)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Chatbot_base_chatbot_producto_v2_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Chatbot_base_chatbot_producto_v2_2\\assets\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model.save('Chatbot_base_chatbot_producto_v2_2',save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tf.data.Dataset.from_tensor_slices(np.array(train_x)).take(1):\n",
    "#     print (i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_y).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_x).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(np.array(train_x)[0]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(128, input_shape=(len(train_x[0]), ),\n",
    "#                 activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(len(train_y[0]), \n",
    "#                 activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=sgd, metrics=['accuracy'])\n",
    "# hist = model.fit(np.array(train_x), np.array(train_y),\n",
    "#                  epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
